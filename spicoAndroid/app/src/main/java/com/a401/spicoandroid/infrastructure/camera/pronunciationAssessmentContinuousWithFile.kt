package com.a401.spicoandroid.infrastructure.camera

import android.content.Context
import com.microsoft.cognitiveservices.speech.*
import com.microsoft.cognitiveservices.speech.audio.AudioConfig
import com.microsoft.cognitiveservices.speech.PronunciationAssessmentGradingSystem
import com.microsoft.cognitiveservices.speech.PronunciationAssessmentGranularity
import android.media.MediaPlayer
import android.util.Log
import com.a401.spicoandroid.BuildConfig.AZURE_KEY
import com.a401.spicoandroid.BuildConfig.AZURE_REGION
import androidx.core.net.toUri
import java.io.File

fun pronunciationAssessmentContinuousWithFile(
    context: Context,
    audioFile: File,
    script: String): Map<String, Any> {
    // Azure Speech ì„œë¹„ìŠ¤ ì„¤ì •
    val subscriptionKey = AZURE_KEY
    val serviceRegion = AZURE_REGION

    val speechConfig = SpeechConfig.fromSubscription(subscriptionKey, serviceRegion)
    val audioConfig = AudioConfig.fromWavFileInput(audioFile.absolutePath)

    // í‰ê°€í•  í…ìŠ¤íŠ¸
    val referenceText = script

    // ë°œìŒ í‰ê°€ êµ¬ì„±
    val pronConfig = PronunciationAssessmentConfig(referenceText,
        PronunciationAssessmentGradingSystem.HundredMark,
        PronunciationAssessmentGranularity.Phoneme, true)
    pronConfig.enableProsodyAssessment()

    val recognizer = SpeechRecognizer(speechConfig, "ko-KR", audioConfig)

    pronConfig.applyTo(recognizer)
    Log.d("AzurePronunciation", "âœ… ë°œìŒ í‰ê°€ ì ìš© ì™„ë£Œ")


    var done = false
    var fullText = ""

    val pauseIssues = mutableListOf<Pair<Long, Long>>()
    val speedIssues = mutableListOf<Pair<Long, Long>>() // ë§ì´ ë„ˆë¬´ ë¹ ë¥´ê±°ë‚˜ ëŠë¦° êµ¬ê°„
    val volumeIssues = mutableListOf<Pair<Long, Long>>() // ëª©ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ í° êµ¬ê°„
    val pronunciationIssues = mutableListOf<Pair<Long, Long>>() // ë°œìŒ ì •í™•ë„ê°€ ë‚®ì€ êµ¬ê°„

    var prevOffset: Long? = null

    val recognizedWords = mutableListOf<String>()
    var accuracyTotal = 0.0
    var completenessTotal = 0.0
    var fluencyTotal = 0.0
    var pronunciationTotal = 0.0
    var wordCount = 0

    recognizer.sessionStopped.addEventListener { _, _ ->
        done = true
    }

    recognizer.recognized.addEventListener { _, e ->
        fullText += e.result.text + " "
        Log.d("AzurePronunciation", "ğŸ¤ ì¸ì‹ë¨: ${e.result.text}")

        val pronResult = PronunciationAssessmentResult.fromResult(e.result)
        Log.d("AzurePronunciation", "ğŸ”¹ ì •í™•ë„=${pronResult.accuracyScore}, ìœ ì°½ì„±=${pronResult.fluencyScore}, ë°œìŒ=${pronResult.pronunciationScore}")

        accuracyTotal += pronResult.accuracyScore
        completenessTotal += pronResult.completenessScore
        fluencyTotal += pronResult.fluencyScore
        pronunciationTotal += pronResult.pronunciationScore
        wordCount++

        for (word in pronResult.words) {
            recognizedWords.add(word.word)
            val offset = word.offset
            val duration = word.duration
            val endOffset = offset + duration

            Log.d("AzurePronunciation", "ğŸ”¹ ë‹¨ì–´ ì¸ì‹: ${word.word} (Offset=$offset, Duration=$duration)")

            if (word.accuracyScore < 60) {
                pronunciationIssues.add(offset to (offset + duration))
                Log.w("AzurePronunciation", "âš ï¸ ë°œìŒ ì •í™•ë„ê°€ ë‚®ìŒ: ${word.word} (${word.accuracyScore})")
            }

            if (prevOffset != null) {
                val pause = offset - (prevOffset!! + duration)
                if (pause > 3000000) {
                    pauseIssues.add(prevOffset!! to offset)
                }
            }

            prevOffset = offset
        }
    }


    try {
        recognizer.startContinuousRecognitionAsync().get()
        Log.d("AzurePronunciation", "ğŸš€ STT ì‹œì‘ë¨")
    } catch (e: Exception) {
        Log.e("AzurePronunciation", "âŒ ë°œìŒ í‰ê°€ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${e.message}")
    }

    Log.d("AzurePronunciation", "ğŸš€ ë°œìŒ í‰ê°€ ì§„í–‰ ì¤‘...")


    val mediaPlayer = MediaPlayer().apply {
        setDataSource(context, audioFile.absolutePath.toUri())
        prepare() // ğŸ”¹ ì¤€ë¹„ í›„ ì‹¤í–‰
    }

    if (!mediaPlayer.isPlaying) {
        Log.w("AzurePronunciation", "âš ï¸ MediaPlayerê°€ ì¬ìƒë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ AudioSessionIdë¥¼ í˜¸ì¶œí•˜ë ¤ í•¨!")
    }


    val duration = mediaPlayer.duration.toLong() // ms ë‹¨ìœ„

    while (!done && duration > 0) {
        Thread.sleep(1000)
    }

    recognizer.stopContinuousRecognitionAsync().get()
    Log.d("AzurePronunciation", "âœ… ë°œìŒ í‰ê°€ ì™„ë£Œ")

    val volumeLevel = try {
        mediaPlayer.audioSessionId.toDouble() // ğŸ”¹ ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥
    } catch (e: IllegalStateException) {
        Log.e("AzurePronunciation", "âŒ MediaPlayer ì˜¤ë¥˜ ë°œìƒ: ${e.message}")
        50.0 // ê¸°ë³¸ê°’ ë°˜í™˜
    }
    mediaPlayer.release()

    var totalPauseTime = 0L
    pauseIssues.forEach { (start, end) ->
        totalPauseTime += end - start
    }
    val penalty = totalPauseTime / 100L // ì˜ˆ: 1ì´ˆë‹¹ 10ì  ê°ì 
    val pauseScore = (100 - penalty).coerceIn(60, 100)


    val volumeScore = when {
        volumeLevel in 30.0..70.0 -> 100
        volumeLevel < 30.0 -> 80
        else -> 70
    }

    val speechRate = recognizedWords.size / (duration / 1000.0)
    val speedScore = when {
        speechRate in 1.5..3.0 -> 100
        speechRate < 1.5 -> 80.also { speedIssues.add(0L to duration) }
        else -> 70.also { speedIssues.add(0L to duration) }
    }

    val accuracyAvg = accuracyTotal / wordCount
    val completenessAvg = completenessTotal / wordCount
    val fluencyAvg = fluencyTotal / wordCount
    val pronunciationAvg = pronunciationTotal / wordCount

    fun formatTime(tick: Long): String {
        val ms = tick / 10_000 // 100ns -> ms
        val minutes = ms / 60000
        val seconds = (ms % 60000) / 1000
        return String.format("%02d:%02d", minutes, seconds)
    }

    val issueDetails = mapOf(
        "pauseIssues" to pauseIssues.map { formatTime(it.first) to formatTime(it.second) },
        "speedIssues" to speedIssues.map { formatTime(it.first) to formatTime(it.second) },
        "volumeIssues" to volumeIssues.map { formatTime(it.first) to formatTime(it.second) },
        "pronunciationIssues" to pronunciationIssues.map { formatTime(it.first) to formatTime(it.second) }
    )

    Log.d("AzurePronunciation", "ğŸ“ ìµœì¢… ë¶„ì„ ê²°ê³¼: $issueDetails")


    return mapOf(
        "transcribedText" to fullText.trim(),
        "accuracyScore" to accuracyAvg,
        "completenessScore" to completenessAvg,
        "fluencyScore" to fluencyAvg,
        "pronunciationScore" to pronunciationAvg,
        "pauseScore" to pauseScore,
        "volumeScore" to volumeScore,
        "speedScore" to speedScore,
        "issueDetails" to issueDetails
    )
}